@article{vanes2024,
  title={“Your friendly AI assistant”: the anthropomorphic self-representations of ChatGPT and its implications for imagining AI},
  author={van Es, Karin and Nguyen, Dennis},
  journal={AI \& SOCIETY},
  pages={1--13},
  year={2024},
  publisher={Springer}
}

@article{FARHOOD2024100293,
title = {Advancing student outcome predictions through generative adversarial networks},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100293},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100293},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000961},
author = {Helia Farhood and Ibrahim Joudah and Amin Beheshti and Samuel Muller},
keywords = {Artificial intelligence in education, Generative AI in education, AI-based student outcome prediction, Learning performance prediction, Generative adversarial networks in education},
abstract = {Predicting student outcomes is essential in educational analytics for creating personalised learning experiences. The effectiveness of these predictive models relies on having access to sufficient and accurate data. However, privacy concerns and the lack of student consent often restrict data collection, limiting the applicability of predictive models. To tackle this obstacle, we employ Generative Adversarial Networks, a type of Generative AI, to generate tabular data replicating and enlarging the dimensions of two distinct publicly available student datasets. The ‘Math dataset’ has 395 observations and 33 features, whereas the ‘Exam dataset’ has 1000 observations and 8 features. Using advanced Python libraries, Conditional Tabular Generative Adversarial Networks and Copula Generative Adversarial Networks, our methodology consists of two phases. First, a mirroring approach where we produce synthetic data matching the volume of the real datasets, focusing on privacy and evaluating predictive accuracy. Second, augmenting the real datasets with newly created synthetic observations to fill gaps in datasets that lack student data. We validate the synthetic data before employing these approaches using Correlation Analysis, Density Analysis, Correlation Heatmaps, and Principal Component Analysis. We then compare the predictive accuracy of whether students will pass or fail their exams across original, synthetic, and augmented datasets. Employing Feedforward Neural Networks, Convolutional Neural Networks, and Gradient-boosted Neural Networks, and using Bayesian optimisation for hyperparameter tuning, this research methodically examines the impact of synthetic data on prediction accuracy. We implement and optimize these models using Python. Our mirroring approach aims to achieve accuracy rates that closely align with the original data. Meanwhile, our augmenting approach seeks to reach a slightly higher accuracy level than when solely learning from the original data. Our findings provide actionable insights into leveraging advanced Generative AI techniques to enhance educational outcomes and meet our objectives successfully.}
}

@article{abbasItHarmfulHelpful2024,
  title = {Is It Harmful or Helpful? {{Examining}} the Causes and Consequences of Generative {{AI}} Usage among University Students},
  shorttitle = {Is It Harmful or Helpful?},
  author = {Abbas, Muhammad and Jam, Farooq Ahmed and Khan, Tariq Iqbal},
  year = {2024},
  month = feb,
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {21},
  number = {1},
  pages = {10},
  issn = {2365-9440},
  doi = {10.1186/s41239-024-00444-7},
  urldate = {2024-05-28},
  abstract = {While the discussion on generative artificial intelligence, such as ChatGPT, is making waves in academia and the popular press, there is a need for more insight into the use of ChatGPT among students and the potential harmful or beneficial consequences associated with its usage. Using samples from two studies, the current research examined the causes and consequences of ChatGPT usage among university students. Study 1 developed and validated an eight-item scale to measure ChatGPT usage by conducting a survey among university students (N\,=\,165). Study 2 used a three-wave time-lagged design to collect data from university students (N\,=\,494) to further validate the scale and test the study's hypotheses. Study 2 also examined the effects of academic workload, academic time pressure, sensitivity to rewards, and sensitivity to quality on ChatGPT usage. Study 2 further examined the  effects of ChatGPT usage on students' levels of procrastination, memory loss, and academic performance. Study 1 provided evidence for the validity and reliability of the ChatGPT usage scale. Furthermore, study 2 revealed that when students faced higher academic workload and time pressure, they were more likely to use ChatGPT. In contrast,~students who were sensitive to rewards were less likely to use ChatGPT. Not surprisingly, use of ChatGPT was likely to develop tendencies for procrastination and memory loss and dampen the students' academic performance. Finally, academic workload, time pressure, and sensitivity to rewards had indirect effects on students' outcomes through ChatGPT usage.},
  keywords = {Academic performance,ChatGPT usage,Memory loss,Procrastination,Sensitivity to quality,Sensitivity to rewards,Time pressure,Workload},
  file = {/Users/Vink0109/Zotero/storage/TID7UUPR/Abbas et al. - 2024 - Is it harmful or helpful Examining the causes and.pdf;/Users/Vink0109/Zotero/storage/XWCHL2IY/s41239-024-00444-7.html}
}

@misc{aliswensonElectionDisinformationTakes2024,
  title = {Election Disinformation Takes a Big Leap with {{AI}} Being Used to Deceive Worldwide},
  author = {{Ali Swenson} and {Kelvin Chan}},
  year = {2024},
  month = mar,
  journal = {AP News},
  urldate = {2024-05-28},
  abstract = {A wave of AI deepfakes has coursed through social media for months, serving as a warning for more than 50 countries heading to the polls this year.},
  chapter = {World News},
  howpublished = {https://apnews.com/article/artificial-intelligence-elections-disinformation-chatgpt-bc283e7426402f0b4baa7df280a4c3fd},
  langid = {english},
  file = {/Users/Vink0109/Zotero/storage/CE5455VH/artificial-intelligence-elections-disinformation-chatgpt-bc283e7426402f0b4baa7df280a4c3fd.html}
}

@article{alkaissi2023artificial,
  title = {Artificial Hallucinations in {{ChatGPT}}: Implications in Scientific Writing},
  author = {Alkaissi, Hussam and McFarlane, Samy I},
  year = {2023},
  journal = {Cur{\=e}us},
  volume = {15},
  number = {2},
  publisher = {Cureus}
}

@article{alkaissi2023artificial,
  title = {Artificial Hallucinations in {{ChatGPT}}: Implications in Scientific Writing},
  author = {Alkaissi, Hussam and McFarlane, Samy I},
  year = {2023},
  journal = {Cur{\=e}us},
  volume = {15},
  number = {2}
}

@article{athaluri2023exploring,
  title = {Exploring the Boundaries of Reality: Investigating the Phenomenon of Artificial Intelligence Hallucination in Scientific Writing through {{ChatGPT}} References},
  author = {Athaluri, Sai Anirudh and Manthena, Sandeep Varma and Kesapragada, VSR Krishna Manoj and Yarlagadda, Vineel and Dave, Tirth and Duddumpudi, Rama Tulasi Siri},
  year = {2023},
  journal = {Cur{\=e}us},
  volume = {15},
  number = {4},
  publisher = {Cureus}
}

@article{athaluri2023exploring,
  title = {Exploring the Boundaries of Reality: Investigating the Phenomenon of Artificial Intelligence Hallucination in Scientific Writing through {{ChatGPT}} References},
  author = {Athaluri, Sai Anirudh and Manthena, Sandeep Varma and Kesapragada, VSR Krishna Manoj and Yarlagadda, Vineel and Dave, Tirth and Duddumpudi, Rama Tulasi Siri},
  year = {2023},
  journal = {Cur{\=e}us},
  volume = {15},
  number = {4}
}

@inproceedings{baldassarre2023,
  title = {The Social Impact of Generative {{AI}}: {{An}} Analysis on {{ChatGPT}}},
  booktitle = {Proceedings of the 2023 {{ACM}} Conference on Information Technology for Social Good},
  author = {Baldassarre, Maria Teresa and Caivano, Danilo and Fernandez Nieto, Berenice and Gigante, Domenico and Ragone, Azzurra},
  year = {2023},
  series = {{{GoodIT}} '23},
  pages = {363--373},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3582515.3609555},
  abstract = {In recent months, the impact of Artificial Intelligence (AI) on citizens' lives has gained considerable public interest, driven by the emergence of Generative AI models, ChatGPT in particular. The rapid development of these models has sparked heated discussions regarding their benefits, limitations, and associated risks. Generative models hold immense promise across multiple domains, such as healthcare, finance, and education, to cite a few, presenting diverse practical applications. Nevertheless, concerns about potential adverse effects have elicited divergent perspectives, ranging from privacy risks to escalating social inequality. This paper adopts a methodology to delve into the societal implications of Generative AI tools, focusing primarily on the case of ChatGPT. It evaluates the potential impact on several social sectors and illustrates the findings of a comprehensive literature review of both positive and negative effects, emerging trends, and areas of opportunity of Generative AI models. This analysis aims to facilitate an in-depth discussion by providing insights that can inspire policy, regulation, and responsible development practices to foster a citizen-centric AI.},
  isbn = {9798400701160},
  keywords = {Citizen-centric AI,Generative AI Social Impact,Trustable AI}
}

@inproceedings{baldassarre2023,
  title = {The Social Impact of Generative {{AI}}: {{An}} Analysis on {{ChatGPT}}},
  booktitle = {Proceedings of the 2023 {{ACM}} Conference on Information Technology for Social Good},
  author = {Baldassarre, Maria Teresa and Caivano, Danilo and Fernandez Nieto, Berenice and Gigante, Domenico and Ragone, Azzurra},
  year = {2023},
  series = {{{GoodIT}} '23},
  pages = {363--373},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3582515.3609555},
  abstract = {In recent months, the impact of Artificial Intelligence (AI) on citizens' lives has gained considerable public interest, driven by the emergence of Generative AI models, ChatGPT in particular. The rapid development of these models has sparked heated discussions regarding their benefits, limitations, and associated risks. Generative models hold immense promise across multiple domains, such as healthcare, finance, and education, to cite a few, presenting diverse practical applications. Nevertheless, concerns about potential adverse effects have elicited divergent perspectives, ranging from privacy risks to escalating social inequality. This paper adopts a methodology to delve into the societal implications of Generative AI tools, focusing primarily on the case of ChatGPT. It evaluates the potential impact on several social sectors and illustrates the findings of a comprehensive literature review of both positive and negative effects, emerging trends, and areas of opportunity of Generative AI models. This analysis aims to facilitate an in-depth discussion by providing insights that can inspire policy, regulation, and responsible development practices to foster a citizen-centric AI.},
  isbn = {9798400701160},
  keywords = {Citizen-centric AI,Generative AI Social Impact,Trustable AI}
}

@inproceedings{berthelot2023,
  title = {Estimating the Environmental Impact of {{Generative-AI}} Services Using an {{LCA-based}} Methodology},
  booktitle = {{{CIRP LCE}} 2024 - 31st Conference on Life Cycle Engineering},
  author = {Berthelot, Adrien and Caron, Eddy and Jay, Mathilde and Lef{\`e}vre, Laurent},
  year = {2024},
  month = jun,
  pages = {1--10},
  address = {Turin, Italy},
  hal_id = {hal-04346102},
  hal_version = {v2},
  keywords = {Digital services,Energy,Generative AI,Greenhouse Gas Emission,Life Cycle Analysis,Methodology}
}

@inproceedings{berthelot2023,
  title = {Estimating the Environmental Impact of {{Generative-AI}} Services Using an {{LCA-based}} Methodology},
  booktitle = {{{CIRP LCE}} 2024 - 31st Conference on Life Cycle Engineering},
  author = {Berthelot, Adrien and Caron, Eddy and Jay, Mathilde and Lef{\`e}vre, Laurent},
  year = {2024},
  month = jun,
  pages = {1--10},
  address = {Turin, Italy},
  keywords = {Digital services,Energy,Generative AI,Greenhouse Gas Emission,Life Cycle Analysis,Methodology}
}

@article{bockting2023,
  title = {Living Guidelines for Generative {{AI}} --- Why Scientists Must Oversee Its Use},
  author = {Bockting, Claudi and Dis, Eva A and Rooij, Robert and Zuidema, Willem and Bollen, Johan},
  year = {2023},
  month = oct,
  journal = {Nature},
  volume = {622},
  pages = {693--696},
  doi = {10.1038/d41586-023-03266-1}
}

@article{bockting2023,
  title = {Living Guidelines for Generative {{AI}} --- Why Scientists Must Oversee Its Use},
  author = {Bockting, Claudi and Dis, Eva A and Rooij, Robert and Zuidema, Willem and Bollen, Johan},
  year = {2023},
  month = oct,
  journal = {Nature},
  volume = {622},
  pages = {693--696},
  doi = {10.1038/d41586-023-03266-1}
}

@article{chan2023policy,
  title = {A Comprehensive {{AI}} Policy Education Framework for University Teaching and Learning},
  author = {Chan, Cecilia Ka Yuk},
  year = {2023},
  journal = {International journal of educational technology in higher education},
  volume = {20},
  number = {1},
  pages = {38},
  publisher = {Springer}
}

@article{chan2023policy,
  title = {A Comprehensive {{AI}} Policy Education Framework for University Teaching and Learning},
  author = {Chan, Cecilia Ka Yuk},
  year = {2023},
  journal = {International journal of educational technology in higher education},
  volume = {20},
  number = {1},
  pages = {38}
}

@inproceedings{chien2023,
  title = {Reducing the Carbon Impact of Generative {{AI}} Inference (Today and in 2035)},
  booktitle = {Proceedings of the 2nd Workshop on Sustainable Computer Systems},
  author = {Chien, Andrew A and Lin, Liuzixuan and Nguyen, Hai and Rao, Varsha and Sharma, Tristan and Wijayawardana, Rajini},
  year = {2023},
  series = {{{HotCarbon}} '23},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3604930.3605705},
  abstract = {Generative AI, exemplified in ChatGPT, Dall-E 2, and Stable Diffusion, are exciting new applications consuming growing quantities of computing. We study the compute, energy, and carbon impacts of generative AI inference. Using ChatGPT as an exemplar, we create a workload model and compare request direction approaches (Local, Balance, CarbonMin), assessing their power use and carbon impacts.Our workload model shows that for ChatGPT-like services, inference dominates emissions, in one year producing 25x the carbon-emissions of training GPT-3. The workload model characterizes user experience, and experiments show that carbon emissions-aware algorithms (CarbonMin) can both maintain user experience and reduce carbon emissions dramatically (35\%). We also consider a future scenario (2035 workload and power grids), and show that CarbonMin can reduce emissions by 56\%. In both cases, the key is intelligent direction of requests to locations with low-carbon power. Combined with hardware technology advances, CarbonMin can keep emissions increase to only 20\% compared to 2022 levels for 55x greater workload. Finally we consider datacenter headroom to increase effectiveness of shifting. With headroom, CarbonMin reduces 2035 emissions by 71\%.},
  articleno = {11},
  isbn = {9798400702426},
  keywords = {carbon emissions,generative AI,geographic shifting,large language models,sustainability}
}

@inproceedings{chien2023,
  title = {Reducing the Carbon Impact of Generative {{AI}} Inference (Today and in 2035)},
  booktitle = {Proceedings of the 2nd Workshop on Sustainable Computer Systems},
  author = {Chien, Andrew A and Lin, Liuzixuan and Nguyen, Hai and Rao, Varsha and Sharma, Tristan and Wijayawardana, Rajini},
  year = {2023},
  series = {{{HotCarbon}} '23},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3604930.3605705},
  abstract = {Generative AI, exemplified in ChatGPT, Dall-E 2, and Stable Diffusion, are exciting new applications consuming growing quantities of computing. We study the compute, energy, and carbon impacts of generative AI inference. Using ChatGPT as an exemplar, we create a workload model and compare request direction approaches (Local, Balance, CarbonMin), assessing their power use and carbon impacts.Our workload model shows that for ChatGPT-like services, inference dominates emissions, in one year producing 25x the carbon-emissions of training GPT-3. The workload model characterizes user experience, and experiments show that carbon emissions-aware algorithms (CarbonMin) can both maintain user experience and reduce carbon emissions dramatically (35\%). We also consider a future scenario (2035 workload and power grids), and show that CarbonMin can reduce emissions by 56\%. In both cases, the key is intelligent direction of requests to locations with low-carbon power. Combined with hardware technology advances, CarbonMin can keep emissions increase to only 20\% compared to 2022 levels for 55x greater workload. Finally we consider datacenter headroom to increase effectiveness of shifting. With headroom, CarbonMin reduces 2035 emissions by 71\%.},
  isbn = {9798400702426},
  keywords = {carbon emissions,generative AI,geographic shifting,large language models,sustainability}
}

@book{duin2021writing,
  title = {Writing Futures: {{Collaborative}}, Algorithmic, Autonomous},
  author = {Duin, Ann Hill and Pedersen, Isabel},
  year = {2021},
  publisher = {Springer}
}

@book{duin2021writing,
  title = {Writing Futures: {{Collaborative}}, Algorithmic, Autonomous},
  author = {Duin, Ann Hill and Pedersen, Isabel},
  year = {2021},
  publisher = {Springer}
}

@article{eliza,
  title = {{{ELIZA}}---a Computer Program for the Study of Natural Language Communication between Man and Machine},
  author = {Weizenbaum, Joseph},
  year = {1966},
  month = jan,
  journal = {Communications of The Acm},
  volume = {9},
  number = {1},
  pages = {36--45},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0001-0782},
  doi = {10.1145/365153.365168},
  issue_date = {Jan. 1966}
}

@article{eliza,
  title = {{{ELIZA}}---a Computer Program for the Study of Natural Language Communication between Man and Machine},
  author = {Weizenbaum, Joseph},
  year = {1966},
  month = jan,
  journal = {Communications of The Acm},
  volume = {9},
  number = {1},
  pages = {36--45},
  issn = {0001-0782},
  doi = {10.1145/365153.365168}
}

@article{habibHowDoesGenerative2024,
  title = {How Does Generative Artificial Intelligence Impact Student Creativity?},
  author = {Habib, Sabrina and Vogel, Thomas and Anli, Xiao and Thorne, Evelyn},
  year = {2024},
  month = apr,
  journal = {Journal of Creativity},
  volume = {34},
  number = {1},
  pages = {100072},
  issn = {2713-3745},
  doi = {10.1016/j.yjoc.2023.100072},
  urldate = {2024-05-28},
  abstract = {This study aimed to learn about the impact of generative artificial intelligence (AI) on student creative thinking skills and subsequently provide instructors with information on how to guide the use of AI for creative growth within classroom instruction. This mixed methods study used qualitative and quantitative data collected through an AUT test conducted in a college-level creativity course. The authors measured flexibility, fluency, elaboration, and originality of the data to assess the impact of ChatGPT-3 on students' divergent thinking. The results advocate for a careful approach in integrating AI into creative education. While AI has the potential to significantly support creative thinking, there are also negative impacts on creativity and creative confidence. The authors of this study believe that creativity is central to learning, developing students' ability to respond to challenges and find solutions within any field; thus the results of this study can be applicable to any classroom faced with the impact and/or integrating the use of AI on idea generation.},
  keywords = {Alternative uses Task (AUT),Artificial intelligence (AI),Creative confidence,Creative process,Creative thinking,Higher education,Mixed methods}
}

@article{heersminkUseLargeLanguage2024,
  title = {Use of Large Language Models Might Affect Our Cognitive Skills},
  author = {Heersmink, Richard},
  year = {2024},
  month = mar,
  journal = {Nature Human Behaviour},
  pages = {1--2},
  publisher = {Nature Publishing Group},
  issn = {2397-3374},
  doi = {10.1038/s41562-024-01859-y},
  urldate = {2024-05-28},
  abstract = {Large language models can generate sophisticated text or code with little input from a user, which has the potential to impoverish our own writing and thinking skills. We need to understand the effect of this technology on our cognition and to decide whether this is what we want.},
  copyright = {2024 Springer Nature Limited},
  langid = {english},
  keywords = {Ethics,Philosophy}
}

@misc{Installation,
  title = {Installation :},
  shorttitle = {Installation},
  journal = {Better BibTeX for Zotero},
  urldate = {2024-04-10},
  abstract = {Make Zotero more useful for us LaTeX holdouts},
  howpublished = {https://retorque.re/zotero-better-bibtex/installation/index.html},
  langid = {english}
}

@article{kangPreventionHandlingMissing2013,
  title = {The Prevention and Handling of the Missing Data},
  author = {Kang, Hyun},
  year = {2013},
  journal = {Korean Journal of Anesthesiology},
  volume = {64},
  number = {5},
  pages = {402},
  issn = {2005-6419, 2005-7563},
  doi = {10.4097/kjae.2013.64.5.402},
  urldate = {2024-03-13},
  langid = {english}
}

@misc{knawNederlandseGedragscodeWetenschappelijke2018,
  title = {{Nederlandse gedragscode wetenschappelijke integriteit}},
  author = {{KNAW} and {NFU} and {NWO} and {TO2-Federatie} and {Vereniging Hogescholen} and {VSNU}},
  year = {2018},
  publisher = {{Data Archiving and Networked Services (DANS)}},
  doi = {10.17026/DANS-2CJ-NVWU},
  urldate = {2024-05-28},
  copyright = {info:eu-repo/semantics/openAccess, Creative Commons Zero v1.0 Universal},
  langid = {dutch},
  keywords = {Interdisciplinary sciences}
}

@misc{knawNederlandseGedragscodeWetenschappelijke2018,
  title = {{Nederlandse gedragscode wetenschappelijke integriteit}},
  author = {{KNAW} and {NFU} and {NWO} and {TO2-Federatie} and {Vereniging Hogescholen} and {VSNU}},
  year = {2018},
  publisher = {{Data Archiving and Networked Services (DANS)}},
  doi = {10.17026/DANS-2CJ-NVWU},
  urldate = {2024-05-28},
  copyright = {info:eu-repo/semantics/openAccess, Creative Commons Zero v1.0 Universal},
  langid = {dutch},
  keywords = {Interdisciplinary sciences}
}

@inproceedings{kokkuAugmentingClassroomsAI2018,
  title = {Augmenting {{Classrooms}} with {{AI}} for {{Personalized Education}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Kokku, Ravi and Sundararajan, Sharad and Dey, Prasenjit and Sindhgatta, Renuka and Nitta, Satya and Sengupta, Bikram},
  year = {2018},
  month = apr,
  pages = {6976--6980},
  issn = {2379-190X},
  doi = {10.1109/ICASSP.2018.8461812},
  urldate = {2024-05-28},
  abstract = {Intelligent tutoring systems (ITS) have been a topic of great interest for about five decades. Over the years, ITS research has leveraged AI advancements, and has also helped push the boundaries of AI capabilities with grounded usage scenarios. Using ITSs along with classroom instruction to augment traditional teaching is a canonical example of how humans and machines can work together to solve problems that are otherwise overwhelming and non-scalable individually. The experiences of personalized learning created by (1) seamless orchestration of human decision-making at few critical points with (2) scalability of cognitive capabilities using AI systems can drive increased student engagement leading to improved learning outcomes. By considering two particular use-cases of early childhood learning and higher education, we discuss the challenges involved in designing these complex human-centric systems. These systems integrate technologies involving interactivity, dialog, automated question generation, and learning analytics.},
  keywords = {AI in Education,Artificial intelligence,Assessments,Collaboration,Dialog-based tutoring,Education,Intelligent tutoring systems,ITS,Man-machine systems,Natural languages,Space exploration,Task analysis}
}

@article{kumar2023faculty,
  title = {Faculty Members' Use of Artificial Intelligence to Grade Student Papers: A Case of Implications},
  author = {Kumar, Rahul},
  year = {2023},
  journal = {International Journal for Educational Integrity},
  volume = {19},
  number = {1},
  pages = {9},
  publisher = {Springer}
}

@article{kumar2023faculty,
  title = {Faculty Members' Use of Artificial Intelligence to Grade Student Papers: A Case of Implications},
  author = {Kumar, Rahul},
  year = {2023},
  journal = {International Journal for Educational Integrity},
  volume = {19},
  number = {1},
  pages = {9}
}

@misc{lyttonAIHiringTools2024,
  title = {{{AI}} Hiring Tools May Be Filtering out the Best Job Applicants},
  author = {Lytton, Charlotte},
  year = {2024},
  urldate = {2024-05-28},
  abstract = {As firms increasingly rely on artificial intelligence-driven hiring platforms, many highly qualified candidates are finding themselves on the cutting room floor.},
  howpublished = {https://www.bbc.com/worklife/article/20240214-ai-recruiting-hiring-software-bias-discrimination},
  langid = {english},
  file = {/Users/Vink0109/Zotero/storage/Z6UPS5Z2/20240214-ai-recruiting-hiring-software-bias-discrimination.html}
}

@misc{mekelapanditharatneHowAIPuts2023,
  title = {How {{AI Puts Elections}} at {{Risk}} --- {{And}} the {{Needed Safeguards}} {\textbar} {{Brennan Center}} for {{Justice}}},
  author = {{Mekela Panditharatne} and {Noah Giansiracusa}},
  year = {2023},
  month = oct,
  urldate = {2024-05-28},
  howpublished = {https://www.brennancenter.org/our-work/analysis-opinion/how-ai-puts-elections-risk-and-needed-safeguards},
  langid = {english},
  file = {/Users/Vink0109/Zotero/storage/4QXUH4S2/how-ai-puts-elections-risk-and-needed-safeguards.html}
}

@article{Ostergaard2023,
  title = {False Responses from Artificial Intelligence Models Are Not Hallucinations},
  author = {{\O}stergaard, S{\o}ren Dinesen and Nielbo, Kristoffer Laigaard},
  year = {2023},
  month = may,
  journal = {Schizophrenia Bulletin},
  volume = {49},
  number = {5},
  eprint = {https://academic.oup.com/schizophreniabulletin/article-pdf/49/5/1105/51375568/sbad068.pdf},
  pages = {1105--1107},
  issn = {0586-7614},
  doi = {10.1093/schbul/sbad068},
  abstract = {As recently highlighted in the New England Journal of Medicine,1,2 artificial intelligence (AI) has the potential to revolutionize the field of medicine. While AI undoubtedly represents a set of extremely powerful technologies, it is not infallible. Accordingly, in their illustrative paper on potential medical applications of the recently launched large language model GPT-4, Lee et al. point out that chatbot applications for this AI-driven large language model occasionally produce false responses and that ``A false response by GPT-4 is sometimes referred to as a `hallucination,'.''1 Indeed, it has become standard in AI to refer to a response that is not justified by the training data as a hallucination.3 We find this terminology to be problematic for the following 2 reasons:}
}

@article{Ostergaard2023,
  title = {False Responses from Artificial Intelligence Models Are Not Hallucinations},
  author = {{\O}stergaard, S{\o}ren Dinesen and Nielbo, Kristoffer Laigaard},
  year = {2023},
  month = may,
  journal = {Schizophrenia Bulletin},
  volume = {49},
  number = {5},
  pages = {1105--1107},
  issn = {0586-7614},
  doi = {10.1093/schbul/sbad068},
  abstract = {As recently highlighted in the New England Journal of Medicine,1,2 artificial intelligence (AI) has the potential to revolutionize the field of medicine. While AI undoubtedly represents a set of extremely powerful technologies, it is not infallible. Accordingly, in their illustrative paper on potential medical applications of the recently launched large language model GPT-4, Lee et al. point out that chatbot applications for this AI-driven large language model occasionally produce false responses and that ``A false response by GPT-4 is sometimes referred to as a `hallucination,'.''1 Indeed, it has become standard in AI to refer to a response that is not justified by the training data as a hallucination.3 We find this terminology to be problematic for the following 2 reasons:}
}

@article{REF,
  title = {{{THERE IS A MISSING REFERENCE}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  year = {2017},
  journal = {Advances in neural information processing systems},
  volume = {30}
}

@article{REF,
  title = {{{THERE IS A MISSING REFERENCE}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  year = {2017},
  journal = {Advances in neural information processing systems},
  volume = {30}
}

@techreport{roschelleAIFutureLearning2020,
  title = {{{AI}} and the {{Future}} of {{Learning}}: {{Expert Panel Report}}},
  shorttitle = {{{AI}} and the {{Future}} of {{Learning}}},
  author = {Roschelle, Jeremy and Lester, James and Fusco, Judi},
  year = {2020},
  month = nov,
  journal = {Digital Promise},
  institution = {Digital Promise},
  urldate = {2024-05-28},
  abstract = {This report is based on the discussion that emerged from a convening of a panel of 22 experts in artificial intelligence (AI) and in learning. It introduces three layers that can frame the meaning of AI for educators. First, AI can be seen as "computational intelligence" and capability can be brought to bear on educational challenges as an additional resource to an educator's abilities and strengths. Second, AI brings specific, exciting new capabilities to computing, including sensing, recognizing patterns, representing knowledge, making and acting on plans, and supporting naturalistic interactions with people. Third, AI can be used as a toolkit to enable us to imagine, study, and discuss futures for learning that don't exist today. Experts voiced the opinion that the most impactful uses of AI in education have not yet been invented. The report enumerates important strengths and weaknesses of AI, as well as the respective opportunities and barriers to applying AI to learning. Through discussions among experts about these layers, we observed new design concepts for using AI in learning. The panel also made seven recommendations for future research priorities. [The report was also created with the Center for Integrative Research in Computing and Learning Sciences (CIRCLS), the University of Pittsburgh, and NC State University.]},
  langid = {english},
  keywords = {Artificial Intelligence,Computation,Design,Educational Assessment,Educational Benefits,Educational Research,Educational Trends,Futures (of Society),Interaction,Learning,Technology Uses in Education},
  annotation = {ERIC Number: ED614308},
  file = {/Users/Vink0109/Zotero/storage/FJA2AMPN/Roschelle et al. - 2020 - AI and the Future of Learning Expert Panel Report.pdf}
}

@article{sunDeepLearningConventional2023,
  title = {Deep Learning versus Conventional Methods for Missing Data Imputation: {{A}} Review and Comparative Study},
  shorttitle = {Deep Learning versus Conventional Methods for Missing Data Imputation},
  author = {Sun, Yige and Li, Jing and Xu, Yifan and Zhang, Tingting and Wang, Xiaofeng},
  year = {2023},
  month = oct,
  journal = {Expert Systems with Applications},
  volume = {227},
  pages = {120201},
  issn = {09574174},
  doi = {10.1016/j.eswa.2023.120201},
  urldate = {2024-03-13},
  langid = {english}
}

@incollection{turing,
  title = {Lecture on the Automatic Computing Engine (1947)},
  booktitle = {The Essential Turing},
  author = {Turing, Alan},
  year = {2004},
  month = sep,
  eprint = {https://academic.oup.com/book/0/chapter/355745788/chapter-pdf/43816995/isbn-9780198250791-book-part-15.pdf},
  publisher = {Oxford University Press},
  doi = {10.1093/oso/9780198250791.003.0015},
  abstract = {On 8 December 1943 the world's first large-scale special-purpose electronic digital computer---`Colossus', as it became known---went into operation at the Government Code and Cypher School (see `Computable Numbers: A Guide', `Enigma', and the introduction to Chapter 4). Colossus was built by Thomas H. Flowers and his team of engineers at the Post Office Research Station in Doll is Hill, London. Until relatively recently, few had any idea that electronic digital computation was used successfully during the Second World War, since those who built and worked with Colossus were prohibited by the Official Secrets Act from sharing their knowledge. Colossus contained approximately the same number of electronic valves (vacuum tubes) as von Neumann's IAS computer, built at the Princeton Institute of Advanced Study and dedicated in 1952. The IAS computer was forerunner of the IBM 701, the company's first mass-produced stored-programme electronic computer (1953). The first Colossus had 1,600 electronic valves and Colossus II, installed in mid-1944, 2,400, while the IAS computer had 2,600. Colossus lacked two important features of modern computers. First, it had no internally stored programmes (see `Computable Numbers: A Guide'). To set up Colossus for a new task, the operators had to alter the machine's physical wiring, using plugs and switches. Second, Colossus was not a general-purpose machine, being designed for a specific cryptanalytic task (involving only logical operations and counting). Nevertheless, Flowers had established decisively and for the first time that large-scale electronic computing machinery was practicable. The implication of Flowers's racks of electronic equipment would have been obvious to Turing. Once Turing had seen Colossus it was, Flowers said, just a matter of Turing's waiting to see what opportunity might arise to put the idea of his universal computing machine into practice. Precisely such an opportunity fell into Turing's lap in 1945, when John Womersley invited him to join the Mathematics Division of the National Physical Laboratory (NPL) at Teddington in London, in order to design and develop an electronic stored-programme digital computer---a concrete form of the universal Turing machine of 1936.},
  isbn = {978-0-19-825079-1}
}

@incollection{turing,
  title = {Lecture on the Automatic Computing Engine (1947)},
  booktitle = {The Essential Turing},
  author = {Turing, Alan},
  year = {2004},
  month = sep,
  publisher = {Oxford University Press},
  doi = {10.1093/oso/9780198250791.003.0015},
  abstract = {On 8 December 1943 the world's first large-scale special-purpose electronic digital computer---`Colossus', as it became known---went into operation at the Government Code and Cypher School (see `Computable Numbers: A Guide', `Enigma', and the introduction to Chapter 4). Colossus was built by Thomas H. Flowers and his team of engineers at the Post Office Research Station in Doll is Hill, London. Until relatively recently, few had any idea that electronic digital computation was used successfully during the Second World War, since those who built and worked with Colossus were prohibited by the Official Secrets Act from sharing their knowledge. Colossus contained approximately the same number of electronic valves (vacuum tubes) as von Neumann's IAS computer, built at the Princeton Institute of Advanced Study and dedicated in 1952. The IAS computer was forerunner of the IBM 701, the company's first mass-produced stored-programme electronic computer (1953). The first Colossus had 1,600 electronic valves and Colossus II, installed in mid-1944, 2,400, while the IAS computer had 2,600. Colossus lacked two important features of modern computers. First, it had no internally stored programmes (see `Computable Numbers: A Guide'). To set up Colossus for a new task, the operators had to alter the machine's physical wiring, using plugs and switches. Second, Colossus was not a general-purpose machine, being designed for a specific cryptanalytic task (involving only logical operations and counting). Nevertheless, Flowers had established decisively and for the first time that large-scale electronic computing machinery was practicable. The implication of Flowers's racks of electronic equipment would have been obvious to Turing. Once Turing had seen Colossus it was, Flowers said, just a matter of Turing's waiting to see what opportunity might arise to put the idea of his universal computing machine into practice. Precisely such an opportunity fell into Turing's lap in 1945, when John Womersley invited him to join the Mathematics Division of the National Physical Laboratory (NPL) at Teddington in London, in order to design and develop an electronic stored-programme digital computer---a concrete form of the universal Turing machine of 1936.},
  isbn = {978-0-19-825079-1}
}

@misc{utrechtuniversityCodesConductOrganisation2024,
  title = {Codes of Conduct - {{Organisation}} - {{Utrecht University}}},
  author = {{Utrecht University}},
  year = {2024},
  urldate = {2024-05-28},
  abstract = {Utrecht University has established specific regulations governing conduct.},
  howpublished = {https://www.uu.nl/en/organisation/about-us/codes-of-conduct},
  langid = {english}
}

@misc{utrechtuniversityGenerativeAIEducation2024,
  title = {Generative {{AI}} - {{Education}} - {{Utrecht University}}},
  author = {{Utrecht University}},
  year = {2024},
  urldate = {2024-05-28},
  abstract = {Artificial intelligence is having an increasing impact on our society and therefore education.},
  howpublished = {https://www.uu.nl/en/education/education-at-uu/teaching/generative-ai},
  langid = {english},
  file = {/Users/Vink0109/Zotero/storage/P48EIVC8/generative-ai.html}
}

@article{vaswani,
  title = {Attention Is All You Need},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  year = {2017},
  journal = {Advances in neural information processing systems},
  volume = {30}
}

@article{vaswani,
  title = {Attention Is All You Need},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  year = {2017},
  journal = {Advances in neural information processing systems},
  volume = {30}
}

@misc{vink2024open,
  title = {Gerkovink/Openeducationbook: {{Open}} Education in Higher Education},
  author = {Vink, Gerko and Veen, Duco and Oberman, Hanne},
  year = {2024},
  month = jan,
  doi = {10.5281/zenodo.10594358},
  howpublished = {Zenodo}
}

@misc{vink2024open,
  title = {Gerkovink/Openeducationbook: {{Open}} Education in Higher Education},
  author = {Vink, Gerko and Veen, Duco and Oberman, Hanne},
  year = {2024},
  month = jan,
  publisher = {Zenodo},
  doi = {10.5281/zenodo.10594358}
}

@article{ziwei,
  title = {Survey of Hallucination in Natural Language Generation},
  author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  year = {2023},
  month = mar,
  journal = {Acm Computing Surveys},
  volume = {55},
  number = {12},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0360-0300},
  doi = {10.1145/3571730},
  abstract = {Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation, and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before.In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions, and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.},
  articleno = {248},
  issue_date = {December 2023},
  keywords = {consistency in NLG,extrinsic hallucination,factuality in NLG,faithfulness in NLG,Hallucination,intrinsic hallucination}
}

@article{ziwei,
  title = {Survey of Hallucination in Natural Language Generation},
  author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  year = {2023},
  month = mar,
  journal = {Acm Computing Surveys},
  volume = {55},
  number = {12},
  issn = {0360-0300},
  doi = {10.1145/3571730},
  abstract = {Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation, and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before.In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions, and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.},
  keywords = {consistency in NLG,extrinsic hallucination,factuality in NLG,faithfulness in NLG,Hallucination,intrinsic hallucination}
}

@article{zotero-2,
  type = {Article}
}
